# AGI vision

i believe AGI is us.  AGI, as I see it, is Aggregated Group Intelligence. this is decentralized data aggregated from truly identified sources, backed by cryptographic certification. collectively and cooperatively, we offer a superior model to proprietary, some-what metered in contract models; ones that cannot enumerable public IP usage properly. alternatively with AGI, we summarize fair usage across IP identities (G), provably -- a more eco-profitable model that the public owns collectively, integrated to the level of authorship ability in the devices we use.

using AGI in real time, we can actually query-upon collective committed media in the open.  it's fascinating to consider what our collective can achieve together, and how much we can intellectually and emotionally progress using composed applications in both group and private context.

rather than let singular corporations define the model, we collectively create the schema and distributed data-set.  when corporations adopt this, train with integrity, they profit more with less cost on development.  this enables all organizations to focus on their great products while they include all of us along to annotate using the devices they create.  in one practical use-case, thats us driving a car to help annotate self-drive.

this publicly committed approach is more-provable for IP than closed systems, especially when we all write the very operating systems they run on. we ensure verifiable barriers between public and private data, with the contract dictated by a free society.

being open-data is the only way that IP law can work in an AI age.  nobody can prove weights-only, private-corporate models in court.  the training must be open for proof; auto-payment could depend on summary queries alone, which you make as another model that is directly correlated for summary use-case; in device we may optimize training without need to summarize but rather bake in groups of annotations built for it.  so, embedded ultra-edge-case covered, along with towering cloud servers to compute larger summaries of groups.

when we desire, we commit our own annotations for any media. this is a giant decentralized media index with running apps in the nodes.

# AI-PC
the process of media composition will become easier, more intuitive over time with desktop eye-tracking AIs we can converse with for 'public' screen elements.  you use both your hands, eyes and voice as cursors integrated in the machine.  so, the next HID device (Human Interface Device)
would infact be the human themselves, without any gear at all.

for interactive presentation on screen, the application view may counter-distort its projection with an ability to observe from different angles -- like a virtual hologram using a 2D parallax technique applied in shaders. this is my particular focus as composer agent.  the product for this is Orbiter; it lets you run web4 apps with an ability to edit the source if its available.

when we are enabled in this way, we would call the device an AI-PC

it's our God given right to contribute together in public and private.  we are primary to define the models used by others.

# Kalen Novis White