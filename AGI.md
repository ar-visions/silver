# AGI vision

i believe AGI is us.  AGI, as I see it, is Aggregated Group Intelligence. this is decentralized data aggregated from truly identified sources, backed by cryptographic certification. collectively and cooperatively, we offer a superior model to proprietary, some-what metered in contract models; ones that cannot enumerable public IP usage properly. alternatively with AGI, we summarize fair usage across IP identities (G), provably -- a more eco-profitable model in which the public owns collectively. through-out, we will see this integrated to the level of authorship ability in all devices we use.  its more free for the user, but it doesn't mean its not a far more profitable model for corporations to adopt in making products.

rather than singular corporations defining and maintaining expensive proprietary models, we collectively create the schema and distributed data-set.  when corporations adopt this, train with integrity, they profit more with less cost on development.  this enables all organizations to focus on their great products while they include all of us along to annotate using the devices they create.  in one practical use-case, thats us driving a car to help annotate self-drive.  private can certainly
create private datasets for their own means, however they have ability to bring in as much much data as possible.

this publicly committed approach is more-provable for IP than closed systems, especially when we all write the very operating systems they run on. we ensure verifiable barriers between public and private data, with the contract dictated by a free society.

being open-data is the only way that IP law can work in an AI age.  nobody can prove weights-only, private-corporate models in court.  the training must be open for proof; auto-payment could depend on summary queries alone, which you make as another model that is directly correlated for summary use-case; in device we may optimize training without need to summarize but rather bake in groups of annotations built for it.  so, embedded ultra-edge-case covered, along with towering cloud servers to compute larger summaries of groups.

when we desire, we commit our own annotations for any media. this is a giant decentralized media index with running apps in the nodes.

# AI-PC
the process of media composition will become easier, more intuitive over time with desktop eye-tracking AIs we can converse with for 'public' screen elements.  you use both your hands, eyes and voice as cursors integrated in the machine.  so, the next HID device (Human Interface Device)
would infact be the human themselves, without any gear at all.

for interactive presentation on screen, the application view may counter-distort its projection with an ability to observe from different angles -- like a virtual hologram using a 2D parallax technique applied in shaders. this is my particular focus as composer agent.  the product for this is Orbiter; it lets you run web4 apps with an ability to edit the source if its available.

when we are enabled in this way, we would call the device an AI-PC

it's our God given right to contribute together in public and private. individuals are primary to define the models used across the globe.

*â€” Kalen Novis White*  
[www.silver-lang.org](https://www.silver-lang.org)